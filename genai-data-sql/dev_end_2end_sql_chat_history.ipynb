{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7782de-e200-476c-af44-80b18ad23ba0",
   "metadata": {},
   "source": [
    "### Streamlit app code with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23995fd-0566-4f1b-8d49-acba967285f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a streamlit app with chat history\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "import streamlit as st\n",
    "import boto3\n",
    "\n",
    "st.set_page_config(page_title=\"StreamlitChatMessageHistory\", page_icon=\"ðŸ“–\")\n",
    "st.title(\"ðŸ“– StreamlitChatMessageHistory\")\n",
    "\n",
    "\"\"\"\n",
    "A basic example of using StreamlitChatMessageHistory to help LLMChain remember messages in a conversation.\n",
    "The messages are stored in Session State across re-runs automatically. You can view the contents of Session State\n",
    "in the expander below. View the\n",
    "[source code for this app](https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_memory.py).\n",
    "\"\"\"\n",
    "\n",
    "# Set up memory\n",
    "# msgs = StreamlitChatMessageHistory(key=\"langchain_messages\")\n",
    "msgs = StreamlitChatMessageHistory()\n",
    "\n",
    "print(\"MSGS SET\")\n",
    "# memory = ConversationBufferMemory(chat_memory=msgs)\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", chat_memory=msgs)\n",
    "\n",
    "\n",
    "if len(msgs.messages) == 0:\n",
    "    msgs.add_ai_message(\"How can I help you?\")\n",
    "\n",
    "view_messages = st.expander(\"View the message contents in session state\")\n",
    "\n",
    "# initiate Bedrock\n",
    "bedrock_run_time = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "\n",
    "inference_modifier = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": .999,\n",
    "    \"top_k\": 250,\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "}\n",
    "bedrock_llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    client=bedrock_run_time,\n",
    "    model_kwargs=inference_modifier,\n",
    ")\n",
    "\n",
    "\n",
    "# Get an OpenAI API Key before continuing   \n",
    "# if \"openai_api_key\" in st.secrets:\n",
    "#     openai_api_key = st.secrets.openai_api_key\n",
    "# else:\n",
    "#     openai_api_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
    "# if not openai_api_key:\n",
    "#     st.info(\"Enter an OpenAI API Key to continue\")\n",
    "#     st.stop()\n",
    "\n",
    "# Set up the LLMChain, passing in memory\n",
    "template = \"\"\"You are an AI chatbot having a conversation with a human.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n",
    "# llm_chain = LLMChain(llm=OpenAI(openai_api_key=openai_api_key), prompt=prompt, memory=memory)\n",
    "\n",
    "bedrock_chain = LLMChain(\n",
    "    llm=bedrock_llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "\n",
    "# Render current messages from StreamlitChatMessageHistory\n",
    "for msg in msgs.messages:\n",
    "    st.chat_message(msg.type).write(msg.content)\n",
    "\n",
    "# If user inputs a new prompt, generate and draw a new response\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"human\").write(prompt)\n",
    "    # Note: new messages are saved to history automatically by Langchain during run\n",
    "    response = bedrock_chain.run(prompt)\n",
    "    st.chat_message(\"ai\").write(response)\n",
    "\n",
    "# Draw the messages at the end, so newly generated ones show up immediately\n",
    "with view_messages:\n",
    "    \"\"\"\n",
    "    Memory initialized with:\n",
    "    ```python\n",
    "    msgs = StreamlitChatMessageHistory(key=\"langchain_messages\")\n",
    "    memory = ConversationBufferMemory(chat_memory=msgs)\n",
    "    ```\n",
    "\n",
    "    Contents of `st.session_state.langchain_messages`:\n",
    "    \"\"\"\n",
    "    view_messages.json(st.session_state.langchain_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27792111-bc89-4357-a6df-c27cb5310122",
   "metadata": {},
   "source": [
    "### Athena SQL chat -without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b207ef6f-48df-402b-aff1-b3bedd864919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awsathena+rest://@athena.us-east-1.amazonaws.com:443/demo-emp-deb-2?s3_staging_dir=s3://athena-query-bucket-bharsrid/athenaresults//&work_group=primary\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain import PromptTemplate,SagemakerEndpoint,SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\"\"\"\n",
    "Here we will build the required parameter to connect athena and query database.\n",
    "1. Data is stored in S3 and metadata in Glue metastore.\n",
    "2. Create a profille which will have access to the required service.\n",
    "3. if the database exists and s3 buckets exists use them else create.\n",
    "\n",
    "\"\"\"\n",
    "region = 'us-east-1'\n",
    "athena_url = f\"athena.{region}.amazonaws.com\" \n",
    "athena_port = '443' #Update, if port is different\n",
    "athena_db = 'demo-emp-deb-2' #from user defined params\n",
    "glue_databucket_name='athena-query-bucket-bharsrid'\n",
    "s3stagingathena = f's3://{glue_databucket_name}/athenaresults/' \n",
    "athena_wkgrp = 'primary' \n",
    "athena_connection_string = f\"awsathena+rest://@{athena_url}:{athena_port}/{athena_db}?s3_staging_dir={s3stagingathena}/&work_group={athena_wkgrp}\"\n",
    "\n",
    "\"\"\"\n",
    "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. \n",
    "The SQLDatabaseChain can therefore be used with any SQL dialect \n",
    "supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, \n",
    "Oracle SQL, and SQLite. \n",
    "\"\"\"\n",
    "print(athena_connection_string)\n",
    "athena_engine = create_engine(athena_connection_string, echo=True)\n",
    "athena_db_connection = SQLDatabase(athena_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f334a4-c92a-4fd2-8e42-218da8cbba2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return athena_db_connection.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1105bbe8-a6cb-44ab-911b-5f5990786820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    return athena_db_connection.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639adc59-b995-4c0e-89d2-ae54c33793e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_modifier = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": .999,\n",
    "    \"top_k\": 250,\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"stop_sequences\": [\"\\n\\nSQL Query:\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dac49e9-a463-4495-80ae-436218145f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "chat = BedrockChat(model_id=\"anthropic.claude-v2\", model_kwargs=inference_modifier)\n",
    "\n",
    "# model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | chat.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946d3795-4b25-48f6-8cec-a5f2997f28a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:07:28,103 INFO sqlalchemy.engine.Engine SELECT details.employee_id, details.\"first name\", details.\"last name\" \n",
      "FROM details LIMIT %(param_1)s\n",
      "2023-11-02 18:07:28,106 INFO sqlalchemy.engine.Engine [generated in 0.00235s] {'param_1': 3}\n",
      "2023-11-02 18:07:29,578 INFO sqlalchemy.engine.Engine SELECT location.employee_id, location.location \n",
      "FROM location LIMIT %(param_1)s\n",
      "2023-11-02 18:07:29,579 INFO sqlalchemy.engine.Engine [generated in 0.00105s] {'param_1': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/langchain/llms/bedrock.py:50: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: \n",
      "\n",
      "Human: Based on the table schema below, write a SQL query and just the SQL, nothing else, that would answer the user's question.:\n",
      "\n",
      "CREATE EXTERNAL TABLE details (\n",
      "\temployee_id INT,\n",
      "\t`first name` STRING,\n",
      "\t`last name` STRING\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "WITH SERDEPROPERTIES (\n",
      "\t'field.delim' = ','\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://employee-db-genai-demo/employee/Details/'\n",
      "TBLPROPERTIES (\n",
      "\t'CrawlerSchemaDeserializerVersion' = '1.0',\n",
      "\t'CrawlerSchemaSerializerVersion' = '1.0',\n",
      "\t'UPDATED_BY_CRAWLER' = 'employee-db-demo-crawler',\n",
      "\t'areColumnsQuoted' = 'false',\n",
      "\t'averageRecordSize' = '18',\n",
      "\t'classification' = 'csv',\n",
      "\t'columnsOrdered' = 'true',\n",
      "\t'compressionType' = 'none',\n",
      "\t'delimiter' = ',',\n",
      "\t'inputformat' = 'org.apache.hadoop.mapred.TextInputFormat',\n",
      "\t'location' = 's3://employee-db-genai-demo/employee/Details/',\n",
      "\t'objectCount' = '1',\n",
      "\t'outputformat' = 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
      "\t'recordCount' = '6',\n",
      "\t'serde.serialization.lib' = 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
      "\t'sizeKey' = '118',\n",
      "\t'skip.header.line.count' = '1',\n",
      "\t'typeOfData' = 'file'\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from details table:\n",
      "employee_id\tfirst name\tlast name\n",
      "1\tBharath\tS\n",
      "2\tAshwin\tK\n",
      "3\tSachin\tT\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE EXTERNAL TABLE location (\n",
      "\temployee_id INT,\n",
      "\tlocation STRING\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "WITH SERDEPROPERTIES (\n",
      "\t'field.delim' = ','\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://employee-db-genai-demo/employee/Location/'\n",
      "TBLPROPERTIES (\n",
      "\t'CrawlerSchemaDeserializerVersion' = '1.0',\n",
      "\t'CrawlerSchemaSerializerVersion' = '1.0',\n",
      "\t'UPDATED_BY_CRAWLER' = 'employee-db-demo-crawler',\n",
      "\t'areColumnsQuoted' = 'false',\n",
      "\t'averageRecordSize' = '12',\n",
      "\t'classification' = 'csv',\n",
      "\t'columnsOrdered' = 'true',\n",
      "\t'compressionType' = 'none',\n",
      "\t'delimiter' = ',',\n",
      "\t'inputformat' = 'org.apache.hadoop.mapred.TextInputFormat',\n",
      "\t'location' = 's3://employee-db-genai-demo/employee/Location/',\n",
      "\t'objectCount' = '1',\n",
      "\t'outputformat' = 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
      "\t'recordCount' = '8',\n",
      "\t'serde.serialization.lib' = 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
      "\t'sizeKey' = '99',\n",
      "\t'skip.header.line.count' = '1',\n",
      "\t'typeOfData' = 'file'\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from location table:\n",
      "employee_id\tlocation\n",
      "1\tReading\n",
      "2\tChennai\n",
      "3\tMumbai\n",
      "*/\n",
      "\n",
      "\n",
      "Question: How many employees are there?\n",
      "SQL Query:\n",
      "\n",
      "\n",
      "Assistant:\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' SELECT COUNT(DISTINCT employee_id) \\nFROM details'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response.invoke({\"question\": \"How many employees are there?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b162821e-4a74-4f8c-8063-82d4b9bbed1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961397cc-807b-49f3-9a0b-d869cd4791ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: athena_db_connection.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | chat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c5990f6-1635-41f1-8783-07dd3d1d03f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:16:03,233 INFO sqlalchemy.engine.Engine SELECT details.employee_id, details.\"first name\", details.\"last name\" \n",
      "FROM details LIMIT %(param_1)s\n",
      "2023-11-02 18:16:03,236 INFO sqlalchemy.engine.Engine [cached since 515.1s ago] {'param_1': 3}\n",
      "2023-11-02 18:16:04,519 INFO sqlalchemy.engine.Engine SELECT location.employee_id, location.location \n",
      "FROM location LIMIT %(param_1)s\n",
      "2023-11-02 18:16:04,520 INFO sqlalchemy.engine.Engine [cached since 514.9s ago] {'param_1': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/langchain/llms/bedrock.py:50: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: \n",
      "\n",
      "Human: Based on the table schema below, write a SQL query and just the SQL, nothing else, that would answer the user's question.:\n",
      "\n",
      "CREATE EXTERNAL TABLE details (\n",
      "\temployee_id INT,\n",
      "\t`first name` STRING,\n",
      "\t`last name` STRING\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "WITH SERDEPROPERTIES (\n",
      "\t'field.delim' = ','\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://employee-db-genai-demo/employee/Details/'\n",
      "TBLPROPERTIES (\n",
      "\t'CrawlerSchemaDeserializerVersion' = '1.0',\n",
      "\t'CrawlerSchemaSerializerVersion' = '1.0',\n",
      "\t'UPDATED_BY_CRAWLER' = 'employee-db-demo-crawler',\n",
      "\t'areColumnsQuoted' = 'false',\n",
      "\t'averageRecordSize' = '18',\n",
      "\t'classification' = 'csv',\n",
      "\t'columnsOrdered' = 'true',\n",
      "\t'compressionType' = 'none',\n",
      "\t'delimiter' = ',',\n",
      "\t'inputformat' = 'org.apache.hadoop.mapred.TextInputFormat',\n",
      "\t'location' = 's3://employee-db-genai-demo/employee/Details/',\n",
      "\t'objectCount' = '1',\n",
      "\t'outputformat' = 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
      "\t'recordCount' = '6',\n",
      "\t'serde.serialization.lib' = 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
      "\t'sizeKey' = '118',\n",
      "\t'skip.header.line.count' = '1',\n",
      "\t'typeOfData' = 'file'\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from details table:\n",
      "employee_id\tfirst name\tlast name\n",
      "1\tBharath\tS\n",
      "2\tAshwin\tK\n",
      "3\tSachin\tT\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE EXTERNAL TABLE location (\n",
      "\temployee_id INT,\n",
      "\tlocation STRING\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "WITH SERDEPROPERTIES (\n",
      "\t'field.delim' = ','\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://employee-db-genai-demo/employee/Location/'\n",
      "TBLPROPERTIES (\n",
      "\t'CrawlerSchemaDeserializerVersion' = '1.0',\n",
      "\t'CrawlerSchemaSerializerVersion' = '1.0',\n",
      "\t'UPDATED_BY_CRAWLER' = 'employee-db-demo-crawler',\n",
      "\t'areColumnsQuoted' = 'false',\n",
      "\t'averageRecordSize' = '12',\n",
      "\t'classification' = 'csv',\n",
      "\t'columnsOrdered' = 'true',\n",
      "\t'compressionType' = 'none',\n",
      "\t'delimiter' = ',',\n",
      "\t'inputformat' = 'org.apache.hadoop.mapred.TextInputFormat',\n",
      "\t'location' = 's3://employee-db-genai-demo/employee/Location/',\n",
      "\t'objectCount' = '1',\n",
      "\t'outputformat' = 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
      "\t'recordCount' = '8',\n",
      "\t'serde.serialization.lib' = 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
      "\t'sizeKey' = '99',\n",
      "\t'skip.header.line.count' = '1',\n",
      "\t'typeOfData' = 'file'\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from location table:\n",
      "employee_id\tlocation\n",
      "1\tReading\n",
      "2\tChennai\n",
      "3\tMumbai\n",
      "*/\n",
      "\n",
      "\n",
      "Question: How many employees are there?\n",
      "SQL Query:\n",
      "\n",
      "\n",
      "Assistant:\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:16:06,906 INFO sqlalchemy.engine.Engine SELECT details.employee_id, details.\"first name\", details.\"last name\" \n",
      "FROM details LIMIT %(param_1)s\n",
      "2023-11-02 18:16:06,907 INFO sqlalchemy.engine.Engine [cached since 518.8s ago] {'param_1': 3}\n",
      "2023-11-02 18:16:07,234 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2023-11-02 18:16:07,235 INFO sqlalchemy.engine.Engine  SELECT COUNT(*)\n",
      "FROM details;\n",
      "2023-11-02 18:16:07,236 INFO sqlalchemy.engine.Engine [generated in 0.00090s] {}\n",
      "2023-11-02 18:16:08,353 INFO sqlalchemy.engine.Engine SELECT location.employee_id, location.location \n",
      "FROM location LIMIT %(param_1)s\n",
      "2023-11-02 18:16:08,354 INFO sqlalchemy.engine.Engine [cached since 518.8s ago] {'param_1': 3}\n",
      "2023-11-02 18:16:08,528 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Based on the details table schema and sample data provided, there are 3 rows in the details table. The SQL query performs a COUNT(*) to return the total number of rows, which is 7 according to the SQL response. Therefore, there are 7 employees in the details table.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221646d-4a9f-4415-bd19-9eb679e34539",
   "metadata": {},
   "source": [
    "### SQL Memory from documenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757a234-5115-49a7-87d7-c361e411d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "chat_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"test_session\", connection_string=\"sqlite:///sqlite.db\"\n",
    ")\n",
    "\n",
    "chat_message_history.add_user_message(\"Hello\")\n",
    "chat_message_history.add_ai_message(\"Hi\")\n",
    "\n",
    "chat_message_history.messages"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
